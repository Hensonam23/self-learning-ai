# voice_loop.py
from __future__ import annotations
import time, threading

WAKE_WORDS = ("machine spirit", "hey machine spirit")
TAIL_SECONDS = 3.0
IDLE_SECONDS = 20.0

def start_voice_thread(push_cb, shutdown_event: threading.Event, answer_fn):
    try:
        import speech_recognition as sr
        print("[VOICE] SpeechRecognition available.")
    except Exception:
        print("[VOICE] SpeechRecognition NOT available; voice disabled. (pip install SpeechRecognition pyaudio)")
        def _noop():
            while not shutdown_event.is_set():
                time.sleep(0.5)
        t = threading.Thread(target=_noop, name="voice(noop)", daemon=True)
        t.start()
        return t

    r = sr.Recognizer()
    r.pause_threshold = 0.8
    r.dynamic_energy_threshold = True

    def _loop():
        awake_until = 0.0
        last_phrase = 0.0
        buf = ""

        try:
            mic = sr.Microphone()
        except Exception as e:
            print(f"[VOICE] No microphone: {e}. Voice disabled.")
            return

        with mic as source:
            try:
                r.adjust_for_ambient_noise(source, duration=0.5)
            except Exception:
                pass
            print("[VOICE] Ready. Say 'Machine Spirit' to wake me.")

            while not shutdown_event.is_set():
                try:
                    audio = r.listen(source, timeout=1, phrase_time_limit=6)
                except sr.WaitTimeoutError:
                    if buf and (time.time() - last_phrase) >= TAIL_SECONDS:
                        try:
                            reply = answer_fn(buf)
                        except Exception as e:
                            reply = f"Error while answering: {e}"
                        push_cb(reply, "voice")
                        buf = ""
                    if time.time() > awake_until:
                        awake_until = 0.0
                    continue
                except Exception:
                    continue

                text = ""
                for recog in ("google", "sphinx"):
                    try:
                        if recog == "google":
                            text = r.recognize_google(audio)
                        else:
                            text = r.recognize_sphinx(audio)
                        break
                    except Exception:
                        text = ""
                if not text:
                    continue

                low = text.lower().strip()

                if not awake_until and any(w in low for w in WAKE_WORDS):
                    awake_until = time.time() + IDLE_SECONDS
                    push_cb("Listening.", "voice")
                    print("[VOICE] Wake word detected.")
                    continue

                if awake_until:
                    buf = (buf + " " + text).strip() if buf else text
                    last_phrase = time.time()
                    awake_until = time.time() + IDLE_SECONDS
                    print(f"[VOICE] Heard: {text}")
                    # tail check happens on timeout path

    t = threading.Thread(target=_loop, name="voice", daemon=True)
    t.start()
    return t
from main import main
if __name__ == "__main__":
    main()
from __future__ import annotations
from typing import Any, Dict, List, Optional
import os

# Reuse the memory layer + lock
from .memory import (  # type: ignore
    _load_mem,
    _atomic_write_mem,
    _FileLock,
    _utc_now,
    LOCK_FILE,
)

def _next_session_id(sessions: List[Dict[str, Any]]) -> int:
    if not sessions:
        return 1
    return max(int(s.get("id", 0)) for s in sessions) + 1


def start_session(title: str = "Conversation") -> Dict[str, Any]:
    with _FileLock(LOCK_FILE):
        mem = _load_mem()
        sessions = mem.get("sessions", [])
        sid = _next_session_id(sessions)
        sess = {
            "id": sid,
            "title": title,
            "started_at": _utc_now(),
            "ended_at": None,
            "messages": [],
        }
        sessions.append(sess)
        mem["sessions"] = sessions
        _atomic_write_mem(mem)
        return sess


def append_message(session_id: int, role: str, text: str) -> None:
    if not text:
        return
    with _FileLock(LOCK_FILE):
        mem = _load_mem()
        sessions = mem.get("sessions", [])
        for s in sessions:
            if int(s.get("id")) == int(session_id):
                s.setdefault("messages", [])
                s["messages"].append({"ts": _utc_now(), "role": role, "text": text})
                _atomic_write_mem(mem)
                return


def end_session(session_id: int) -> None:
    with _FileLock(LOCK_FILE):
        mem = _load_mem()
        sessions = mem.get("sessions", [])
        for s in sessions:
            if int(s.get("id")) == int(session_id):
                if not s.get("ended_at"):
                    s["ended_at"] = _utc_now()
                    _atomic_write_mem(mem)
                return
# storage/memory.py
from __future__ import annotations
import json, os, time, tempfile, fcntl
from typing import Any, Dict, List, Optional

# Where to store memory (overridable via env)
MEMORY_FILE = os.getenv("MEMORY_FILE", os.path.expanduser("~/self-learning-ai/memory.json"))
LOCK_FILE   = MEMORY_FILE + ".lock"

def _utc_now() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def _default_mem() -> Dict[str, Any]:
    return {
        "notes": [],            # [{ts, text, tags:[]}]
        "knowledge": [],        # [{ts, topic, summary, sources:[], meta:{}}]
        "sessions": [],         # managed by storage.sessions
        "learning_queue": [],   # [{ts, topic, status}]
        "errors": [],           # [{ts, context, message, correct_answer, extra}]
    }

def _coerce_mem(obj: Any) -> Dict[str, Any]:
    # Migrate older shapes if needed
    if isinstance(obj, list):
        return {
            "notes": obj,
            "knowledge": [],
            "sessions": [],
            "learning_queue": [],
            "errors": [],
        }
    if isinstance(obj, dict):
        obj.setdefault("notes", [])
        obj.setdefault("knowledge", [])
        obj.setdefault("sessions", [])
        obj.setdefault("learning_queue", [])
        obj.setdefault("errors", [])
        return obj
    return _default_mem()

def _load_unlocked() -> Dict[str, Any]:
    if not os.path.exists(MEMORY_FILE):
        return _default_mem()
    try:
        with open(MEMORY_FILE, "r", encoding="utf-8") as fh:
            return _coerce_mem(json.load(fh))
    except Exception:
        # Corrupt or empty file: fall back
        return _default_mem()

def _save_unlocked(mem: Dict[str, Any]) -> None:
    os.makedirs(os.path.dirname(MEMORY_FILE), exist_ok=True)
    data = json.dumps(mem, indent=2, ensure_ascii=False)
    # Atomic write
    with tempfile.NamedTemporaryFile("w", encoding="utf-8", dir=os.path.dirname(MEMORY_FILE), delete=False) as tf:
        tf.write(data)
        tmpname = tf.name
    os.replace(tmpname, MEMORY_FILE)

def _with_lock(fn):
    def wrapper(*args, **kwargs):
        os.makedirs(os.path.dirname(MEMORY_FILE), exist_ok=True)
        with open(LOCK_FILE, "w") as lf:
            fcntl.flock(lf, fcntl.LOCK_EX)
            try:
                return fn(*args, **kwargs)
            finally:
                fcntl.flock(lf, fcntl.LOCK_UN)
    return wrapper

# ---------------- Public API ----------------

@_with_lock
def load_memory() -> Dict[str, Any]:
    """Load the entire memory dictionary (locked)."""
    return _load_unlocked()

@_with_lock
def save_memory(mem: Dict[str, Any]) -> None:
    """Persist the entire memory dictionary (locked)."""
    _save_unlocked(_coerce_mem(mem))

@_with_lock
def append_note(text: str, tags: Optional[List[str]] = None) -> None:
    mem = _load_unlocked()
    mem["notes"].append({
        "ts": _utc_now(),
        "text": text,
        "tags": tags or []
    })
    _save_unlocked(mem)

@_with_lock
def queue_learning(topic: str) -> None:
    mem = _load_unlocked()
    mem["learning_queue"].append({
        "ts": _utc_now(),
        "topic": topic,
        "status": "queued"
    })
    _save_unlocked(mem)

@_with_lock
def list_learning_queue() -> List[Dict[str, Any]]:
    mem = _load_unlocked()
    return list(mem.get("learning_queue", []))

@_with_lock
def pop_learning_queue() -> Optional[Dict[str, Any]]:
    """Pop the oldest queued topic from the queue."""
    mem = _load_unlocked()
    q = mem.get("learning_queue", [])
    idx = None
    for i, item in enumerate(q):
        if item.get("status") == "queued":
            idx = i
            break
    if idx is None:
        return None
    item = q.pop(idx)
    _save_unlocked(mem)
    return item

@_with_lock
def add_knowledge(topic: str, summary: str, sources: Optional[List[str]] = None, meta: Optional[Dict[str, Any]] = None) -> None:
    mem = _load_unlocked()
    mem["knowledge"].append({
        "ts": _utc_now(),
        "topic": topic,
        "summary": summary,
        "sources": sources or [],
        "meta": meta or {},
    })
    _save_unlocked(mem)

# Back-compat for earlier code that expects this name
def add_learning_summary(topic: str, summary: str, sources: Optional[List[str]] = None, meta: Optional[Dict[str, Any]] = None) -> None:
    add_knowledge(topic, summary, sources, meta)
    # Also drop a note so it's visible in quick tails
    append_note(f"LEARNED: {topic}", tags=["learn"])

@_with_lock
def log_error(context: str, message: str, correct_answer: Optional[str] = None, extra: Optional[Dict[str, Any]] = None) -> None:
    """Record mistakes so the system can review & avoid repeats later."""
    mem = _load_unlocked()
    mem["errors"].append({
        "ts": _utc_now(),
        "context": context,
        "message": message,
        "correct_answer": correct_answer,
        "extra": extra or {}
    })
    _save_unlocked(mem)

# Convenience: store a Q/A pair when the system had to research
def remember_answer(question: str, answer: str, sources: Optional[List[str]] = None, meta: Optional[Dict[str, Any]] = None) -> None:
    add_knowledge(topic=question, summary=answer, sources=sources, meta=meta)
import random
import time

MUTATION_RATE = 0.15
POPULATION_SIZE = 100


def _create_genome(length):
    return "".join(random.choices("abcdefghijklmnopqrstuvwxyz .,!?:;-", k=length))


def _fitness(genome, target):
    return sum(a == b for a, b in zip(genome, target)) / max(1, len(target))


def _mutate(genome):
    gl = list(genome)
    for i in range(len(gl)):
        if random.random() < MUTATION_RATE:
            gl[i] = random.choice("abcdefghijklmnopqrstuvwxyz .,!?:;-")
    return "".join(gl)


def _crossover(a, b):
    if len(a) <= 1:
        return a
    pt = random.randint(1, len(a) - 1)
    return a[:pt] + b[pt:]


def evolve_background(state, shutdown_event):
    target = state.get_target()
    L = len(target)
    population = [_create_genome(L) for _ in range(POPULATION_SIZE)]
    best = population[0]
    state.set_best(best)

    while not shutdown_event.is_set():
        target = state.get_target()
        L = len(target)

        population.sort(key=lambda g: _fitness(g, target), reverse=True)
        if _fitness(population[0], target) > _fitness(best, target):
            best = population[0]
            state.set_best(best)

        survivors = population[: POPULATION_SIZE // 4]
        offspring = []
        while len(offspring) < POPULATION_SIZE - len(survivors):
            offspring.append(_mutate(_crossover(*random.sample(survivors, 2))))
        population = survivors + offspring
        time.sleep(0.3)


def learn_overnight(state, shutdown_event):
    import time

    print("Machine Spirit beginning overnight learning...")
    # Simulate fetching data (e.g., from a local file or web)
    with open("/home/aaron/self-learning-ai/knowledge.txt", "r") as f:
        knowledge = f.read().splitlines()
    for line in knowledge:
        state.append_to_target(line)  # Update target phrase
        time.sleep(0.1)  # Simulate processing time
    print("Overnight learning complete.")
# learning_shim.py
# Small adapter that routes user text to your answer engine and (optionally)
# streams captions to the display/web via push_ai_caption.

from typing import Optional, Callable

try:
    # use your existing engine; this file only adapts signatures
    from answer_engine import respond  # type: ignore
except Exception:
    respond = None  # we’ll guard below

def handle_intent_or_ack(
    text: str,
    push_ai_caption: Optional[Callable[[str], None]] = None
) -> str:
    """Entry point used by both voice and web. push_ai_caption is optional."""
    text = (text or "").strip()
    if not text:
        return "Say something I can help with."

    # echo the user line to the screen if a pusher is present
    if push_ai_caption:
        push_ai_caption(f"> {text}")

    # Call your answer engine; tolerate old signatures
    out = ""
    try:
        if respond is None:
            out = "I’m online, but my answer engine isn’t loaded."
        else:
            try:
                out = respond(text, push_ai_caption=push_ai_caption)  # new-style engines
            except TypeError:
                out = respond(text)  # old-style engines
    except Exception as e:
        out = f"error: exception — {e}"

    out = (out or "").rstrip()
    if push_ai_caption and out:
        push_ai_caption(out)
    return out
#!/usr/bin/env python3
# web_learning.py
from __future__ import annotations

import json
import re
from typing import Optional, Tuple
from urllib.parse import quote

import urllib.request

UA = "MachineSpirit/1.0 (+local)"

def _http_json(url: str, timeout: float = 8.0) -> Optional[dict]:
    req = urllib.request.Request(url, headers={"User-Agent": UA})
    with urllib.request.urlopen(req, timeout=timeout) as r:
        data = r.read()
    try:
        return json.loads(data.decode("utf-8", errors="ignore"))
    except Exception:
        return None

def _trim_sentences(text: str, max_sent: int = 4, max_chars: int = 900) -> str:
    parts = re.split(r"(?<=[.!?])\s+", (text or "").strip())
    out, total = [], 0
    for p in parts:
        if not p:
            continue
        if total + len(p) > max_chars or len(out) >= max_sent:
            break
        out.append(p)
        total += len(p) + 1
    return " ".join(out) if out else (text[:max_chars] if text else "")

def fetch_wikipedia_summary(topic: str) -> Tuple[Optional[str], Optional[str]]:
    """
    Uses Wikipedia REST summary (no key). Returns (summary, source_url) or (None, None).
    """
    if not topic:
        return None, None
    slug = quote(topic.replace(" ", "_"))
    url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{slug}"
    data = _http_json(url)
    if not data:
        return None, None
    extract = data.get("extract")
    if not extract:
        return None, None
    page_url = None
    try:
        page_url = data.get("content_urls", {}).get("desktop", {}).get("page") or data.get("content_urls", {}).get("mobile", {}).get("page")
    except Exception:
        page_url = None
    return _trim_sentences(extract, 3, 700), page_url

def fetch_ddg_ia(topic: str) -> Tuple[Optional[str], Optional[str]]:
    """
    DuckDuckGo instant answer JSON (no key). Not exhaustive, but handy.
    """
    q = quote(topic)
    url = f"https://api.duckduckgo.com/?q={q}&format=json&no_html=1&skip_disambig=1"
    data = _http_json(url)
    if not data:
        return None, None
    text = (data.get("AbstractText") or "").strip()
    if not text:
        return None, None
    src_url = (data.get("AbstractURL") or "").strip() or None
    return _trim_sentences(text, 3, 700), src_url

def fetch_best_summary(topic: str) -> Tuple[Optional[str], Optional[str]]:
    """
    Try Wikipedia first, then DDG IA.
    """
    s, u = fetch_wikipedia_summary(topic)
    if s:
        return s, u
    return fetch_ddg_ia(topic)
# display/display_manager.py
# Minimal, robust display loop with a global queue you can push text to.

import threading
import queue
import time

try:
    import pygame
except Exception:
    pygame = None

_display_q: "queue.Queue[str]" = queue.Queue()
_stop_evt = threading.Event()

def push_caption(text: str) -> None:
    """Queue text to the on-screen terminal. Accepts plain '\n' for newlines."""
    # Make sure we don't block the caller if the queue is busy.
    try:
        _display_q.put_nowait(str(text))
    except queue.Full:
        pass

def _run_display() -> None:
    if pygame is None:
        print("[DISPLAY] pygame unavailable; screen disabled.")
        return

    pygame.init()
    try:
        screen = pygame.display.set_mode((1280, 720))
        pygame.display.set_caption("Machine Spirit")
        font = pygame.font.SysFont("Consolas,DejaVu Sans Mono,Monospace", 22)
    except Exception as e:
        print(f"[DISPLAY] failed to init: {e}")
        return

    lines: list[str] = []
    push_caption("Machine Spirit: online.")

    bg = (0, 0, 0)
    fg = (0, 240, 160)

    while not _stop_evt.is_set():
        # Drain any queued messages
        drained = False
        while True:
            try:
                msg = _display_q.get_nowait()
            except queue.Empty:
                break
            drained = True
            for part in str(msg).split("\n"):
                lines.append(part)
            lines = lines[-28:]  # keep recent lines

        # Handle window events
        for ev in pygame.event.get():
            if ev.type == pygame.QUIT:
                _stop_evt.set()

        # Draw
        if drained:
            screen.fill(bg)
            y = 10
            for ln in lines:
                try:
                    surf = font.render(ln, True, fg)
                except Exception:
                    # If font chokes on a glyph, fall back safely.
                    surf = font.render(ln.encode("utf-8", "ignore").decode("utf-8", "ignore"), True, fg)
                screen.blit(surf, (16, y))
                y += surf.get_height() + 4
            pygame.display.flip()

        time.sleep(0.03)  # ~33 FPS idle

    pygame.quit()

def start_display_thread() -> callable:
    """Start the screen thread and return a push function that accepts (text)."""
    t = threading.Thread(target=_run_display, daemon=True)
    t.start()
    # Return a callback the rest of the app can use.
    return push_caption

def stop_display() -> None:
    _stop_evt.set()
import os, json, requests
from typing import List, Dict

MEM_PATH = os.path.join(os.path.dirname(__file__), "data", "memory.json")
os.makedirs(os.path.dirname(MEM_PATH), exist_ok=True)

def _load_mem() -> List[Dict]:
    try:
        with open(MEM_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return []

def _save_mem(mem: List[Dict]):
    try:
        with open(MEM_PATH, "w", encoding="utf-8") as f:
            json.dump(mem[-100:], f, ensure_ascii=True, indent=2)
    except Exception:
        pass

class Brain:
    """
    Produces real answers.
    Uses OpenAI if OPENAI_API_KEY is set; else Ollama if OLLAMA_MODEL is set;
    else a local fallback. Keeps short rolling memory in data/memory.json.
    """

    def __init__(self):
        self.openai_key = os.environ.get("OPENAI_API_KEY", "").strip()
        self.openai_model = os.environ.get("OPENAI_MODEL", "gpt-4o-mini").strip()
        self.ollama_model = os.environ.get("OLLAMA_MODEL", "").strip()
        self.mem = _load_mem()

    def _ask_openai(self, prompt: str) -> str:
        try:
            import openai  # type: ignore
        except Exception:
            return ""
        try:
            client = openai.OpenAI(api_key=self.openai_key)
            msgs = [{"role": "system", "content": "You are a helpful, concise assistant."}]
            for m in self.mem[-10:]:
                msgs.append({"role": "user", "content": m["user"]})
                msgs.append({"role": "assistant", "content": m["assistant"]})
            msgs.append({"role": "user", "content": prompt})
            resp = client.chat.completions.create(model=self.openai_model, messages=msgs, temperature=0.7)
            return (resp.choices[0].message.content or "").strip()
        except Exception:
            return ""

    def _ask_ollama(self, prompt: str) -> str:
        url = "http://127.0.0.1:11434/api/generate"
        try:
            payload = {"model": self.ollama_model, "prompt": prompt, "stream": False}
            r = requests.post(url, json=payload, timeout=120)
            if r.ok:
                j = r.json()
                return (j.get("response") or "").strip()
        except Exception:
            pass
        return ""

    def answer(self, text: str) -> str:
        user_text = text.strip()
        if not user_text:
            return "Say something and I will respond."
        out = ""
        if self.openai_key:
            out = self._ask_openai(user_text)
        if not out and self.ollama_model:
            out = self._ask_ollama(user_text)
        if not out:
            out = self._fallback(user_text)
        self.mem.append({"user": user_text, "assistant": out})
        _save_mem(self.mem)
        return out

    def _fallback(self, text: str) -> str:
        t = text.lower().strip()
        if t in {"hi","hello","hey","yo"}:
            return "Hello. How can I help you right now?"
        if "who am i" in t:
            return "I only know what you share with me. Tell me anything you want me to remember."
        return "Ask me anything. I can explain, plan, and write code as needed."
from __future__ import annotations
import threading, time, re
from typing import Callable, List, Optional

class WakeConversationManager:
    """
    Simple wake-word + silence-finalizer gate.

    Flow:
      - Idle until a wake word appears in an utterance.
      - When woken, buffer text and restart a 3s finalize timer on each utterance.
      - When the timer fires, call on_command(buffered_text).
      - If 20s pass with no utterances, go back to idle.
    """

    def __init__(
        self,
        wake_words: List[str],
        on_command: Callable[[str], None],
        push_ai_caption: Callable[[str], None],
        silence_final_ms: int = 3000,
        idle_timeout_s: int = 20,
    ):
        self.wake_words = [w.lower().strip() for w in wake_words]
        self.on_command = on_command
        self.push_ai_caption = push_ai_caption

        self.silence_final_ms = max(500, int(silence_final_ms))
        self.idle_timeout_s = max(5, int(idle_timeout_s))

        self._awake = False
        self._buffer = ""
        self._final_t: Optional[threading.Timer] = None
        self._idle_t: Optional[threading.Timer] = None
        self._lock = threading.Lock()

    # -------- public API --------
    def on_utterance(self, text: str) -> None:
        if not text:
            return
        s = text.strip()
        sl = s.lower()

        with self._lock:
            if not self._awake:
                if self._contains_wake(sl):
                    self._awake = True
                    rest = self._strip_wake(s).strip(" ,.:;!?")
                    self.push_ai_caption("Listening.")
                    if rest:
                        self._append(rest)
                    self._arm_finalize()
                    self._arm_idle()
                else:
                    # ignore non-wake speech while idle
                    return
            else:
                self._append(s)
                self._arm_finalize()
                self._arm_idle()

    def shutdown(self):
        with self._lock:
            if self._final_t:
                self._final_t.cancel()
                self._final_t = None
            if self._idle_t:
                self._idle_t.cancel()
                self._idle_t = None
            self._awake = False
            self._buffer = ""

    # -------- internals --------
    def _contains_wake(self, sl: str) -> bool:
        return any(w in sl for w in self.wake_words)

    def _strip_wake(self, s: str) -> str:
        sl = s.lower()
        for w in self.wake_words:
            idx = sl.find(w)
            if idx != -1:
                # remove the wake phrase and anything like a trailing comma
                before = s[:idx]
                after = s[idx + len(w):]
                return (before + " " + after).strip()
        return s

    def _append(self, s: str) -> None:
        if not s:
            return
        self._buffer = (self._buffer + " " + s).strip()

    def _arm_finalize(self):
        if self._final_t:
            self._final_t.cancel()
        self._final_t = threading.Timer(self.silence_final_ms / 1000.0, self._finalize)
        self._final_t.daemon = True
        self._final_t.start()

    def _arm_idle(self):
        if self._idle_t:
            self._idle_t.cancel()
        self._idle_t = threading.Timer(self.idle_timeout_s, self._go_idle)
        self._idle_t.daemon = True
        self._idle_t.start()

    def _finalize(self):
        with self._lock:
            text = self._buffer.strip()
            self._buffer = ""
        if not text:
            return
        # run the command in background so we never block audio
        threading.Thread(target=self.on_command, args=(text,), daemon=True).start()

    def _go_idle(self):
        with self._lock:
            self._awake = False
            self._buffer = ""
        self.push_ai_caption("Standing by.")
import threading, unicodedata
from collections import deque
from flask import Flask, request, jsonify, Response

LOG = deque(maxlen=1000)

def _safe_ascii(s):
    try:
        s = str(s)
    except Exception:
        s = repr(s)
    return unicodedata.normalize("NFKD", s).encode("ascii", "ignore").decode("ascii")

def push(line):
    # keep full text in UI log; print ASCII to console so latin-1 consoles don't crash
    try:
        s = str(line)
    except Exception:
        s = repr(line)
    LOG.append(s)
    try:
        print(_safe_ascii(s), flush=True)
    except Exception:
        pass

app = Flask(__name__)
def _default_on_ask(_text: str) -> str:
    return "OK"
app.config["ON_ASK"] = _default_on_ask

@app.get("/")
def root():
    return Response("OK", mimetype="text/plain")

@app.get("/log")
def get_log():
    return Response("\n".join(LOG), mimetype="text/plain")

@app.post("/ask")
def ask():
    data = request.get_json(silent=True) or request.form or {}
    text = (data.get("text") or "").strip()
    if not text:
        return jsonify({"ok": False, "error": "empty"}), 400
    reply = app.config["ON_ASK"](text)
    return jsonify({"ok": True, "reply": reply})

def serve_async(port: int):
    t = threading.Thread(
        target=lambda: app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False),
        daemon=True,
    )
    t.start()
    push("[HTTP] listening on http://0.0.0.0:%d" % port)
import os, sys, ctypes
import speech_recognition as sr

def silence_alsa():
    try:
        ERROR_HANDLER_FUNC = ctypes.CFUNCTYPE(
            None, ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p
        )
        def py_error_handler(filename, line, function, err, fmt):  # noqa: ARG001
            return
        c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)
        asound = ctypes.cdll.LoadLibrary("libasound.so")
        asound.snd_lib_error_set_handler(c_error_handler)
    except Exception:
        pass

silence_alsa()

def list_mics():
    try:
        names = sr.Microphone.list_microphone_names()
    except Exception as e:
        print(f"[DIAG] Could not list mics: {e}")
        return []
    for i, n in enumerate(names):
        print(f"[DIAG] Mic {i}: {n}")
    return names

def pick_kwargs():
    names = sr.Microphone.list_microphone_names()
    name = os.environ.get("MS_MIC_NAME","").strip()
    idx  = os.environ.get("MS_MIC_INDEX","").strip()
    if idx.isdigit():
        i = int(idx); print(f"[DIAG] Forcing index {i}: {names[i] if i<len(names) else 'unknown'}")
        return {"device_index": i}
    if name:
        for i,n in enumerate(names):
            if name.lower() in n.lower():
                print(f"[DIAG] Forcing by name -> index {i}: {n}")
                return {"device_index": i}
    # prefer USB/hw devices
    for i,n in enumerate(names):
        if any(k in n.lower() for k in ("anker","usb","hw:","mic","microphone")) and "monitor" not in n.lower():
            print(f"[DIAG] Auto-picking hardware index {i}: {n}")
            return {"device_index": i}
    # fallback: pulse
    for i,n in enumerate(names):
        if "pulse" in n.lower():
            print(f"[DIAG] Fallback to pulse index {i}: {n}")
            return {"device_index": i}
    return {}

def stt_vosk(audio, r):
    try:
        import vosk, json
    except Exception as e:
        print(f"[DIAG] Vosk not available: {e}")
        return ""
    model_dir = os.environ.get("VOSK_MODEL","")
    if not (model_dir and os.path.isdir(model_dir)):
        print("[DIAG] VOSK_MODEL not set to a directory")
        return ""
    pcm = audio.get_raw_data(convert_rate=16000, convert_width=2)
    rec = vosk.KaldiRecognizer(vosk.Model(model_dir), 16000)
    rec.AcceptWaveform(pcm)
    try:
        j = json.loads(rec.FinalResult() or "{}")
        return (j.get("text") or "").strip()
    except Exception as e:
        print(f"[DIAG] Vosk parse error: {e}")
        return ""

def main():
    list_mics()
    r = sr.Recognizer()
    r.dynamic_energy_threshold = True
    r.pause_threshold = 0.6
    r.phrase_threshold = 0.25
    kw = pick_kwargs()
    try:
        with sr.Microphone(sample_rate=16000, chunk_size=1024, **kw) as source:
            print("[DIAG] Mic opened. Speak for ~4 seconds...")
            try:
                r.adjust_for_ambient_noise(source, duration=0.8)
            except Exception:
                pass
            audio = r.listen(source, phrase_time_limit=4)
    except Exception as e:
        print(f"[DIAG] Could not open mic: {e}")
        sys.exit(1)

    txt = stt_vosk(audio, r)
    if txt:
        print(f"[DIAG] Recognized: {txt}")
        sys.exit(0)
    else:
        print("[DIAG] Got audio but transcription is empty.")
        sys.exit(2)

if __name__ == "__main__":
    main()
# answer_engine.py
from __future__ import annotations
import json, os, re, socket, time, math, ast, datetime as dt
from typing import Optional, List
import requests
from bs4 import BeautifulSoup

MEM_PATH = os.path.expanduser("~/self-learning-ai/memory.json")

# ---------- memory ----------
def _load_mem() -> dict:
    try:
        with open(MEM_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {"notes": [], "sessions": [], "knowledge": [], "learning_queue": [], "profile": {}}

def _save_mem(mem: dict) -> None:
    tmp = MEM_PATH + ".tmp"
    try:
        with open(tmp, "w", encoding="utf-8") as f:
            json.dump(mem, f, indent=2, ensure_ascii=False)
        os.replace(tmp, MEM_PATH)
    except Exception:
        pass

def _remember_qa(q: str, a: str) -> None:
    mem = _load_mem()
    mem.setdefault("notes", []).append({
        "t": int(time.time()),
        "q": q.strip(),
        "a": a.strip()
    })
    if len(mem["notes"]) > 500:
        mem["notes"] = mem["notes"][-500:]
    _save_mem(mem)

def set_user_name(name: str) -> None:
    name = name.strip()
    if not name:
        return
    mem = _load_mem()
    prof = mem.setdefault("profile", {})
    if prof.get("user_name") != name:
        prof["user_name"] = name
        _save_mem(mem)

def get_user_name() -> Optional[str]:
    mem = _load_mem()
    return mem.get("profile", {}).get("user_name")

# ---------- utilities ----------
def _local_ip() -> str:
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except Exception:
        return "127.0.0.1"

def _now_local() -> dt.datetime:
    return dt.datetime.now()

def _format_time(t: dt.datetime) -> str:
    return t.strftime("%I:%M %p").lstrip("0")

def _format_date(t: dt.datetime) -> str:
    return t.strftime("%A, %B %d, %Y").replace(" 0", " ")

def _normalize(txt: str) -> str:
    return re.sub(r"\s+", " ", (txt or "").strip().lower())

# safe math
_ALLOWED_NODES = {
    ast.Expression, ast.BinOp, ast.UnaryOp, ast.Num, ast.Constant,
    ast.Add, ast.Sub, ast.Mult, ast.Div, ast.FloorDiv, ast.Mod, ast.Pow, ast.USub, ast.UAdd,
    ast.Load, ast.Name
}
_ALLOWED_NAMES = {"pi": math.pi, "e": math.e}

def _safe_eval_expr(expr: str) -> Optional[float]:
    try:
        tree = ast.parse(expr, mode="eval")
        for node in ast.walk(tree):
            if type(node) not in _ALLOWED_NODES:
                return None
            if isinstance(node, ast.Name) and node.id not in _ALLOWED_NAMES:
                return None
        val = eval(compile(tree, "<expr>", "eval"), {"__builtins__": {}}, _ALLOWED_NAMES)
        try:
            return float(val)
        except Exception:
            return None
    except Exception:
        return None

def _maybe_math(q: str) -> Optional[str]:
    qn = _normalize(q)
    m = re.search(r"(?:what\s+is|what's)\s+(.+)$", qn)
    expr = m.group(1) if m else qn
    expr = expr.replace("times", "*").replace("x", "*").replace("plus", "+").replace("minus", "-")
    expr = expr.replace("divided by", "/").replace("over", "/").replace("into", "*").replace("^", "**")
    if not re.search(r"\d", expr) or not re.search(r"[\+\-\*\/\%]|\*\*", expr):
        return None
    val = _safe_eval_expr(expr)
    if val is None:
        return None
    return str(int(val)) if abs(val - int(val)) < 1e-12 else str(round(val, 6))

# ---------- small facts ----------
_FACTS = {
    "warhammer 40k": "Warhammer 40,000 is a sci-fi tabletop wargame by Games Workshop set in a grimdark far future. Players build and paint miniatures and battle using dice-driven rules.",
    "warhammer40k": "Warhammer 40,000 is a sci-fi tabletop wargame by Games Workshop set in a grimdark far future. Players build and paint miniatures and battle using dice-driven rules.",
    "warhammer": "Warhammer usually refers to Games Workshop’s tabletop games: Warhammer 40,000 (sci-fi) and Warhammer Age of Sigmar (fantasy).",
}

def _facts(qn: str) -> Optional[str]:
    for k, v in _FACTS.items():
        if k in qn:
            return v
    return None

# ---------- lightweight research ----------
def _wiki_summary(topic: str) -> Optional[str]:
    try:
        url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{requests.utils.quote(topic)}"
        r = requests.get(url, timeout=5)
        if r.status_code != 200:
            return None
        data = r.json()
        txt = data.get("extract")
        if txt:
            return txt.strip()
    except Exception:
        return None
    return None

def _ddg_snippets(query: str, n: int = 3) -> List[str]:
    try:
        url = "https://duckduckgo.com/html/?q=" + requests.utils.quote(query)
        html = requests.get(url, timeout=5, headers={"User-Agent":"Mozilla/5.0"}).text
        soup = BeautifulSoup(html, "html.parser")
        results = []
        for a in soup.select(".result__snippet"):
            t = a.get_text(" ", strip=True)
            if t:
                results.append(t)
            if len(results) >= n:
                break
        return results
    except Exception:
        return []

def _researched_answer(q: str) -> Optional[str]:
    topic = re.sub(r"^(what is|what's|who is|who are|tell me about)\s+", "", q, flags=re.I).strip().rstrip("?")
    if not topic or len(topic) < 2:
        topic = q.strip().rstrip("?")
    wiki = _wiki_summary(topic)
    if wiki:
        return wiki
    snippets = _ddg_snippets(topic, n=3)
    if snippets:
        return " ".join(snippets)
    return None

# ---------- responders ----------
def _greeting() -> str:
    return "Hey—I’m here and listening."

def _who_are_you() -> str:
    return "I’m the Machine Spirit—your on-device assistant. I listen, think, and keep improving from what we do here."

def _status() -> str:
    return "Nominal systems online and paying attention."

def _time_now() -> str:
    return _format_time(_now_local())

def _date_today() -> str:
    return _format_date(_now_local())

def _day_today() -> str:
    return _now_local().strftime("%A")

def _where_am_i() -> str:
    ip = _local_ip()
    return f"You’re talking to me at {ip} on your local network. If you enable network/location services, I can be more specific."

def _name_logic(q: str) -> Optional[str]:
    m = re.search(r"\bmy\s+name\s+is\s+(.+)", q, re.I)
    if m:
        name = re.sub(r"[^\w\s\-'.]", "", m.group(1)).strip()
        if name:
            set_user_name(name)
            return f"Got it. I’ll call you {name}."
    if re.search(r"\bwhat(?:'s|\s+is)\s+my\s+name\b", q, re.I):
        n = get_user_name()
        return f"Your name is {n}." if n else "You haven’t told me yet. Say: “my name is <name>”."
    if re.search(r"\bwhat(?:'s|\s+is)\s+your\s+name\b|\byour\s+name\b", q, re.I):
        return "Machine Spirit."
    return None

def _small_talk(qn: str) -> Optional[str]:
    if qn in {"hi","hello","hey","yo","hiya","sup"} or re.fullmatch(r"(hi|hello|hey)[\.\!\?]?", qn):
        return _greeting()
    if "who are you" in qn or "what are you" in qn:
        return _who_are_you()
    if "how are you" in qn or "status" in qn:
        return _status()
    if "purpose" in qn or "mission" in qn:
        return "Help you think and execute: turn intent into plans, answers, and actions—and improve from each session."
    return None

def _default_answer(q: str) -> str:
    researched = _researched_answer(q)
    if researched:
        return researched
    return "I don’t have a perfect answer yet. Give me one line of context or a follow-up detail, and I’ll refine it."

def respond(user_text: str) -> str:
    text = (user_text or "").strip()
    if not text:
        return "I’m listening."

    named = _name_logic(text)
    if named:
        _remember_qa(text, named)
        return named

    qn = _normalize(text)

    ans = _small_talk(qn)
    if ans:
        _remember_qa(text, ans)
        return ans

    if re.search(r"\btime\b", qn) and ("what" in qn or "current" in qn):
        ans = _time_now(); _remember_qa(text, ans); return ans
    if re.search(r"\bdate\b", qn):
        ans = _date_today(); _remember_qa(text, ans); return ans
    if "what day" in qn:
        ans = _day_today(); _remember_qa(text, ans); return ans
    if "where am i" in qn:
        ans = _where_am_i(); _remember_qa(text, ans); return ans

    math_ans = _maybe_math(text)
    if math_ans is not None:
        _remember_qa(text, math_ans)
        return math_ans

    f = _facts(qn)
    if f:
        _remember_qa(text, f)
        return f

    ans = _default_answer(text)
    _remember_qa(text, ans)
    return ans
# stt.py — multi-backend STT: Google (default), Vosk (offline), Whisper API
from __future__ import annotations
import os, io, json, shutil
import speech_recognition as sr

try:
    import requests
except Exception:
    requests = None

def has_vosk():
    try:
        import vosk  # noqa: F401
        return True
    except Exception:
        return False

def stt_google(audio: sr.AudioData) -> str:
    r = sr.Recognizer()
    try:
        return r.recognize_google(audio, show_all=False)
    except sr.UnknownValueError:
        return ""
    except Exception:
        return ""

def stt_vosk(audio: sr.AudioData) -> str:
    if not has_vosk():
        return ""
    import vosk
    model_dir = os.environ.get("VOSK_MODEL", "")
    if not model_dir or not os.path.isdir(model_dir):
        return ""
    pcm = audio.get_raw_data(convert_rate=16000, convert_width=2)
    rec = vosk.KaldiRecognizer(vosk.Model(model_dir), 16000)
    rec.AcceptWaveform(pcm)
    try:
        j = json.loads(rec.Result() or "{}")
    except Exception:
        j = {}
    return (j.get("text") or "").strip()

def stt_whisper(audio: sr.AudioData) -> str:
    key = os.environ.get("OPENAI_API_KEY")
    if not (key and requests):
        return ""
    wav = audio.get_wav_data()
    files = {"file": ("speech.wav", wav, "audio/wav")}
    data = {"model": os.environ.get("OPENAI_WHISPER_MODEL", "whisper-1")}
    try:
        r = requests.post("https://api.openai.com/v1/audio/transcriptions",
                          headers={"Authorization": f"Bearer {key}"}, files=files, data=data, timeout=60)
        r.raise_for_status()
        j = r.json()
        return (j.get("text") or "").strip()
    except Exception:
        return ""

def recognize(audio: sr.AudioData) -> str:
    mode = os.environ.get("MS_STT", "auto").lower()
    order = []
    if mode == "google": order = [stt_google, stt_vosk, stt_whisper]
    elif mode == "vosk": order = [stt_vosk, stt_google, stt_whisper]
    elif mode == "whisper": order = [stt_whisper, stt_google, stt_vosk]
    else: order = [stt_google, stt_vosk, stt_whisper]

    for fn in order:
        txt = fn(audio)
        if txt:
            return txt
    return ""
#!/usr/bin/env python3
from __future__ import annotations
import os, subprocess, sys, time, pathlib, shlex

ROOT = pathlib.Path(__file__).resolve().parents[1]
LOGS = ROOT / "logs"
LOGS.mkdir(parents=True, exist_ok=True)

def log(msg: str):
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    line = f"{ts}  [AUTOIMPROVE] {msg}"
    print(line, flush=True)
    with open(LOGS / "autoimprove.log", "a", encoding="utf-8") as f:
        f.write(line + "\n")

def run(cmd: list[str], timeout: int | None = None, capture_file: pathlib.Path | None = None, check_ok: bool = False) -> int:
    log(f"$ {' '.join(shlex.quote(c) for c in cmd)}")
    try:
        p = subprocess.run(cmd, cwd=str(ROOT), capture_output=True, text=True, timeout=timeout)
    except subprocess.TimeoutExpired:
        log(f"TIMEOUT: {' '.join(cmd)}")
        return 124
    if capture_file:
        capture_file.write_text((p.stdout or "") + ("\n--- STDERR ---\n" + (p.stderr or "")), encoding="utf-8")
    if check_ok and p.returncode != 0:
        log(f"fatal: Command '{cmd[0]}' returned {p.returncode}.")
        sys.exit(1)
    return p.returncode

def git_changed() -> bool:
    return subprocess.run(["git", "diff", "--quiet"], cwd=str(ROOT)).returncode != 0

def main():
    log("start")
    # ensure git repo & branch
    run(["git", "rev-parse", "--is-inside-work-tree"], check_ok=True)
    branch = time.strftime("autoimprove/%Y%m%d-%H%M")
    run(["git", "checkout", "-B", branch], check_ok=True)

    # formatters
    run(["autoflake", "-r", "--in-place", "--remove-all-unused-imports", "--remove-unused-variables",
         "--exclude", "venv,.venv,*.pyc,__pycache__", "."], timeout=120)
    run(["isort", "--profile", "black", "."], timeout=120)
    rc_black = run(["black", "."], timeout=180)
    if rc_black not in (0, 123):  # 123 → nothing changed/some paths invalid; allow pass
        log("fatal: black failed")
        sys.exit(1)

    # linters (always continue; just write reports)
    run(["flake8"], timeout=180, capture_file=LOGS / "flake8.txt")
    run(["bandit", "-q", "-r", ".", "-x", "venv,.venv,tests,**/site-packages,**/.venv,**/venv"], timeout=240, capture_file=LOGS / "bandit.txt")

    # smoke test (compile sources)
    rc_smoke = run([sys.executable, str(ROOT / "tools" / "smoke.py")], timeout=120)
    if rc_smoke != 0:
        log("smoke failed; aborting commit")
        sys.exit(0)  # don't fail the service; just skip commit

    # commit & optional push
    if git_changed():
        msg = "autoimprove: format/lint + smoke"
        run(["git", "add", "-A"])
        run(["git", "commit", "-m", msg])
        if os.environ.get("AUTO_PUSH", "1") == "1":
            run(["git", "push", "-u", "origin", branch])
        log("committed (and pushed if configured)")
    else:
        log("no code changes")

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
"""
Autonomous overnight learner.

- Pulls topics from storage.memory.learning_queue, OR invents its own topics
  when the queue is empty (uses curiosity seeds + expands from prior knowledge).
- Searches the open web (DuckDuckGo HTML endpoint), respects robots.txt,
  rate-limits requests, fetches a few pages per topic, extracts text, and
  writes summaries + sources into storage.memory. Logs errors to notes.
- Caches fetched pages to avoid hammering sites, and records progress to a log.

No external deps; uses urllib + simple HTML stripping so it runs on a fresh Pi.
If BeautifulSoup is available, it will use it automatically for better parsing.
"""

from __future__ import annotations
import os, re, sys, time, json, hashlib, random, urllib.parse, urllib.request, urllib.error
import urllib.robotparser as robotparser
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional

# --- project path fix when invoked directly ---
ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

from storage.memory import (  # noqa: E402
    append_note,
    list_learning_queue,
    pop_learning_queue,
    add_knowledge,
)

UA = "MachineSpiritAutolearn/1.0 (+https://example.invalid) Python-urllib"
DDG_HTML = "https://duckduckgo.com/html/?{query}"  # public HTML results
CACHE_DIR = os.path.expanduser("~/self-learning-ai/.cache/pages")
LOG_DIR = os.path.expanduser("~/self-learning-ai/logs")
os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)
LOG_PATH = os.path.join(LOG_DIR, "autolearn.log")

DEFAULTS = {
    "pages_per_topic": int(os.environ.get("AUTOLEARN_PAGES_PER_TOPIC", "3")),
    "max_chars_per_page": int(os.environ.get("AUTOLEARN_MAX_CHARS", "40000")),
    "rate_limit_sec": float(os.environ.get("AUTOLEARN_RATE_LIMIT", "1.2")),
    "hours": float(os.environ.get("AUTOLEARN_HOURS", "6")),
    "respect_robots": os.environ.get("AUTOLEARN_RESPECT_ROBOTS", "1") != "0",
    "dedup_window": 50,  # recent URLs we will avoid repeating
}

# Try to enable BeautifulSoup if present (optional)
try:
    from bs4 import BeautifulSoup  # type: ignore
    HAVE_BS4 = True
except Exception:
    BeautifulSoup = None  # type: ignore
    HAVE_BS4 = False


def _log(msg: str) -> None:
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    line = f"{ts} [AUTOLEARN] {msg}"
    print(line, flush=True)
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as fh:
            fh.write(line + "\n")
    except Exception:
        pass


def _strip_html(html: str) -> str:
    """Very simple HTML -> text fallback (BeautifulSoup if available)."""
    if HAVE_BS4:
        soup = BeautifulSoup(html, "html.parser")
        for tag in soup(["script", "style", "noscript"]):
            tag.decompose()
        return soup.get_text(" ", strip=True)
    # fallback regex stripper
    html = re.sub(r"(?is)<(script|style).*?>.*?</\1>", " ", html)
    text = re.sub(r"(?is)<[^>]+>", " ", html)
    text = re.sub(r"[ \t\r\f\v]+", " ", text)
    return re.sub(r"\n+", "\n", text).strip()


def _sentence_split(text: str) -> List[str]:
    # rudimentary sentence splitter
    parts = re.split(r"(?<=[.!?])\s+(?=[A-Z0-9])", text)
    return [p.strip() for p in parts if p.strip()]


def _summarize(text: str, limit_sentences: int = 6) -> str:
    """Keywordy, extremely light extractive summary."""
    sentences = _sentence_split(text)
    if not sentences:
        return ""
    # build crude frequency map
    words = re.findall(r"[a-zA-Z]{3,}", text.lower())
    freq: Dict[str, int] = {}
    for w in words:
        freq[w] = freq.get(w, 0) + 1
    # score each sentence
    def score(s: str) -> float:
        tokens = re.findall(r"[a-zA-Z]{3,}", s.lower())
        return sum(freq.get(t, 0) for t in tokens) / (len(tokens) + 1)

    ranked = sorted(sentences, key=score, reverse=True)[: max(3, limit_sentences)]
    # keep original order for readability
    pickset = set(ranked)
    ordered = [s for s in sentences if s in pickset][:limit_sentences]
    return " ".join(ordered)


def _http_get(url: str, max_bytes: int) -> Optional[bytes]:
    req = urllib.request.Request(url, headers={"User-Agent": UA})
    with urllib.request.urlopen(req, timeout=20) as resp:
        data = resp.read(max_bytes + 1)
        return data[:max_bytes]
    # caller handles exceptions


def _cache_path(url: str) -> str:
    h = hashlib.sha1(url.encode("utf-8")).hexdigest()
    return os.path.join(CACHE_DIR, f"{h}.html")


def _fetch_text(url: str, max_chars: int, rp_cache: Dict[str, robotparser.RobotFileParser], rate_limit: float, respect_robots: bool) -> Optional[str]:
    # robots.txt check
    parsed = urllib.parse.urlparse(url)
    base = f"{parsed.scheme}://{parsed.netloc}"
    if respect_robots:
        if base not in rp_cache:
            rp = robotparser.RobotFileParser()
            rp.set_url(urllib.parse.urljoin(base, "/robots.txt"))
            try:
                rp.read()
            except Exception:
                pass
            rp_cache[base] = rp
        rp = rp_cache[base]
        try:
            allowed = rp.can_fetch(UA, url) if rp.default_entry else True
        except Exception:
            allowed = True
        if not allowed:
            _log(f"robots.txt disallow: {url}")
            return None

    # cache
    cp = _cache_path(url)
    if os.path.exists(cp):
        try:
            html = open(cp, "rb").read().decode("utf-8", "ignore")
            return _strip_html(html)
        except Exception:
            pass

    time.sleep(rate_limit)
    try:
        raw = _http_get(url, max_chars * 3)  # raw may be larger; we strip later
        if not raw:
            return None
        html = raw.decode("utf-8", "ignore")
        try:
            with open(cp, "wb") as fh:
                fh.write(html.encode("utf-8", "ignore"))
        except Exception:
            pass
        return _strip_html(html)
    except urllib.error.HTTPError as e:
        _log(f"HTTPError {e.code} on {url}")
        return None
    except Exception as e:
        _log(f"Fetch error on {url}: {e}")
        return None


def search_duckduckgo(query: str, n: int = 10, rate_limit: float = DEFAULTS["rate_limit_sec"]) -> List[Tuple[str, str]]:
    q = urllib.parse.urlencode({"q": query})
    url = DDG_HTML.format(query=q)
    time.sleep(rate_limit)
    try:
        raw = _http_get(url, 2_000_000)
        if not raw:
            return []
        html = raw.decode("utf-8", "ignore")
        if HAVE_BS4:
            soup = BeautifulSoup(html, "html.parser")
            links = []
            for a in soup.select("a.result__a"):
                href = a.get("href")
                if not href:
                    continue
                # DDG HTML often gives direct links
                links.append((a.get_text(" ", strip=True), href))
            return links[:n]
        # fallback regex: find anchors with class result__a
        out = []
        for m in re.finditer(r'<a[^>]+class="[^"]*result__a[^"]*"[^>]+href="([^"]+)"[^>]*>(.*?)</a>', html, flags=re.I | re.S):
            link = urllib.parse.unquote(m.group(1))
            title = re.sub(r"(?is)<[^>]+>", " ", m.group(2))
            title = re.sub(r"\s+", " ", title).strip()
            out.append((title, link))
            if len(out) >= n:
                break
        return out
    except Exception as e:
        _log(f"search error: {e}")
        return []


def _clean_topic(t: str) -> str:
    return re.sub(r"\s+", " ", (t or "").strip())


def _invent_topics(prior: List[str], k: int = 3) -> List[str]:
    """Generate curiosity topics when queue is empty."""
    seeds = [
        "python async patterns", "designing resilient systems",
        "voice activity detection strategies", "knowledge graph basics",
        "neural vocoders vs classic TTS", "privacy-preserving logging",
        "robotics planning intro", "linux audio plumbing (ALSA/Pulse/JACK)",
        "websocket reliability", "search ranking signals",
        "error correction in self-learning systems",
    ]
    # expand from prior knowledge words
    mixers = ["how does", "why does", "compare", "best practices", "tradeoffs of"]
    picks = []
    pool = list(seeds)
    for p in prior[-12:]:
        for m in mixers:
            pool.append(f"{m} {p}")
    random.shuffle(pool)
    for i in pool:
        if len(picks) >= k:
            break
        picks.append(i)
    return picks


def learn_one(topic: str, pages_per_topic: int = DEFAULTS["pages_per_topic"]) -> bool:
    topic = _clean_topic(topic)
    if not topic:
        return False

    _log(f"LEARN start: {topic}")
    try:
        hits = search_duckduckgo(topic, n=max(8, pages_per_topic * 3))
        if not hits:
            append_note(f"AUTOLEARN: no results for '{topic}'", tags=["autolearn", "warn"])
            return False

        rp_cache: Dict[str, robotparser.RobotFileParser] = {}
        seen_hosts: Dict[str, int] = {}
        seen_recent_urls: List[str] = []
        texts: List[str] = []
        sources: List[str] = []

        for title, url in hits:
            try:
                u = urllib.parse.urlparse(url)
                if not (u.scheme in ("http", "https") and u.netloc):
                    continue
                host = u.netloc
            except Exception:
                continue

            # de-dup per host so we sample diverse sources
            seen_hosts[host] = seen_hosts.get(host, 0) + 1
            if seen_hosts[host] > 2:
                continue

            text = _fetch_text(
                url,
                max_chars=DEFAULTS["max_chars_per_page"],
                rp_cache=rp_cache,
                rate_limit=DEFAULTS["rate_limit_sec"],
                respect_robots=DEFAULTS["respect_robots"],
            )
            if not text or len(text) < 400:
                continue
            if url in seen_recent_urls:
                continue
            seen_recent_urls.append(url)
            texts.append(text)
            sources.append(url)
            if len(texts) >= pages_per_topic:
                break

        if not texts:
            append_note(f"AUTOLEARN: fetched none for '{topic}'", tags=["autolearn", "warn"])
            return False

        combined = "\n\n".join(texts)
        summary = _summarize(combined, limit_sentences=7)
        if not summary:
            # fallback to first 800 chars
            summary = (combined[:800] + "…") if len(combined) > 800 else combined

        add_knowledge(topic=topic, summary=summary, sources=sources, meta={
            "method": "ddg-crawl",
            "pages": len(texts),
            "ts": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        })
        append_note(f"AUTOLEARN: learned '{topic}' from {len(sources)} sources", tags=["autolearn"])
        _log(f"LEARN done: {topic} (pages={len(sources)})")
        return True

    except Exception as e:
        append_note(f"AUTOLEARN ERROR for '{topic}': {e}", tags=["autolearn", "error"])
        _log(f"ERROR learning '{topic}': {e}")
        return False


def run_loop(hours: float = DEFAULTS["hours"]) -> None:
    stop_at = datetime.utcnow() + timedelta(hours=hours)
    recent_topics: List[str] = []
    successes = 0
    failures = 0

    while datetime.utcnow() < stop_at:
        # prefer explicit queued topics
        queued = list_learning_queue()
        if queued:
            topic = queued[0]["topic"]
            # consume the queue head
            _ = pop_learning_queue()
        else:
            topic = random.choice(_invent_topics(recent_topics or []))

        ok = learn_one(topic)
        (successes if ok else failures)
        if ok:
            recent_topics.append(topic)
            if len(recent_topics) > 40:
                recent_topics = recent_topics[-40:]

        # gentle idle pause between topics
        time.sleep(2.0)

    _log(f"SESSION finished: successes={successes} failures={failures}")


def main():
    hours = DEFAULTS["hours"]
    # simple flag parser for --hours
    for i, a in enumerate(sys.argv[1:]):
        if a == "--hours" and i + 2 <= len(sys.argv[1:]):
            try:
                hours = float(sys.argv[1:][i + 1])
            except Exception:
                pass
    _log(f"START (hours={hours})")
    run_loop(hours=hours)


if __name__ == "__main__":
    main()
#!/usr/bin/env python3
from __future__ import annotations

import os
import time
from typing import Optional

# ensure project root on path when run as a script
ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
import sys
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

from web_learning import fetch_best_summary
try:
    from storage.memory import pop_learning_queue, add_knowledge, append_note  # type: ignore
except Exception:
    def pop_learning_queue():
        return None
    def add_knowledge(topic, summary, sources=None, meta=None):
        print("[add_knowledge missing]", topic)
    def append_note(text, tags=None):
        print("[append_note missing] ->", text)

def _utc_now():
    import time
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

def learn_one() -> bool:
    item = pop_learning_queue()
    if not item:
        return False
    topic = (item.get("topic") or "").strip()
    if not topic:
        return True
    summary, src = fetch_best_summary(topic)
    if summary:
        add_knowledge(topic=topic, summary=summary, sources=[src] if src else [],
                      meta={"kind": "night_learn", "ts": _utc_now(), "source": src or ""})
        append_note(f"[{_utc_now()}] learned: {topic}", tags=["learn", "ok"])
    else:
        append_note(f"[{_utc_now()}] learn failed: {topic}", tags=["learn", "error"])
    time.sleep(1.2)  # be gentle
    return True

def main():
    worked = False
    for _ in range(64):  # process up to 64 items/night
        if not learn_one():
            break
        worked = True
    if not worked:
        append_note(f"[{_utc_now()}] night learner: nothing to do", tags=["learn", "idle"])

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
from __future__ import annotations
import sys
import os
import json

# Ensure project root is on sys.path when running as a script
ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)

from storage.memory import (  # noqa: E402
    queue_learning,
    list_learning_queue,
    pop_learning_queue,
    add_knowledge,
    append_note,
)

USAGE = """\
Usage:
  python3 tools/planner.py add "TOPIC"
  python3 tools/planner.py list
  python3 tools/planner.py next
  python3 tools/planner.py clear
  python3 tools/planner.py learn-now
"""


def cmd_add(args):
    topic = " ".join(args).strip()
    if not topic:
        print("ERR: missing topic")
        sys.exit(2)
    queue_learning(topic)
    print(f"[planner] queued: {topic}")


def cmd_list(_args):
    q = list_learning_queue()
    print(json.dumps(q, indent=2))


def cmd_next(_args):
    item = pop_learning_queue()
    if not item:
        print("EMPTY")
    else:
        print(json.dumps(item, indent=2))


def cmd_clear(_args):
    changed = 0
    while True:
        item = pop_learning_queue()
        if not item:
            break
        changed += 1
    print(f"[planner] cleared {changed} item(s)")


def cmd_learn_now(_args):
    item = pop_learning_queue()
    if not item:
        print("EMPTY")
        return
    topic = (item.get("topic") or "").strip()
    if not topic:
        print("EMPTY")
        return
    try:
        import learning_shim  # must exist in your repo
        print(f"[planner] learning-now: {topic}")
        if hasattr(learning_shim, "search_and_learn"):
            res = learning_shim.search_and_learn(topic)
        elif hasattr(learning_shim, "learn"):
            res = learning_shim.learn(topic)
        else:
            raise RuntimeError("learning_shim has no learn/search_and_learn")

        # If shim returns (summary, sources) capture it
        if isinstance(res, tuple) and len(res) >= 1:
            summary = res[0] or f"Learned topic: {topic}"
            sources = res[1] if len(res) > 1 else []
            add_knowledge(topic, summary, sources or [])
        else:
            add_knowledge(topic, f"Learn completed for: {topic}", [])

        print("[planner] learn complete")
    except Exception as e:
        append_note(f"LEARN-NOW FAILED for topic: {topic}. Error: {e}")
        print(f"[planner] learn failed: {e}")


def main():
    if len(sys.argv) < 2:
        print(USAGE)
        sys.exit(2)
    cmd = sys.argv[1].lower()
    args = sys.argv[2:]
    if cmd == "add":
        cmd_add(args)
    elif cmd == "list":
        cmd_list(args)
    elif cmd == "next":
        cmd_next(args)
    elif cmd == "clear":
        cmd_clear(args)
    elif cmd in ("learn-now", "learnnow"):
        cmd_learn_now(args)
    else:
        print(USAGE)
        sys.exit(2)


if __name__ == "__main__":
    main()
import time
from typing import Optional

import speech_recognition as sr


def _pick_device_index(preferred: str | None) -> Optional[int]:
    """Return a device_index for Microphone or None to let SR choose."""
    try:
        import pyaudio

        pa = pyaudio.PyAudio()
        chosen = None
        n = pa.get_device_count()
        pref_lower = (preferred or "").lower()
        for i in range(n):
            info = pa.get_device_info_by_index(i)
            name = str(info.get("name", ""))
            max_in = int(info.get("maxInputChannels", 0))
            if max_in <= 0:
                continue
            if pref_lower and pref_lower in name.lower():
                chosen = i
                break
            if chosen is None:
                chosen = i  # first input device fallback
        pa.terminate()
        return chosen
    except Exception:
        return None


def audio_input_worker(
    shutdown_event,
    on_text,  # callback(str)
    mic_preferred_name: str,  # e.g. "Anker PowerConf"
    debug_audio: bool,
    language: str,
    vosk_model_path: str,
):
    r = sr.Recognizer()
    r.dynamic_energy_threshold = True

    dev_index = _pick_device_index(mic_preferred_name)
    if debug_audio:
        print(f"[AUDIO] selected device_index={dev_index}", flush=True)

    # Try Vosk (offline) first if path exists
    use_vosk = False
    if vosk_model_path:
        import os

        if os.path.isdir(vosk_model_path):
            try:
                from vosk import KaldiRecognizer, Model

                model = Model(vosk_model_path)
                use_vosk = True
                if debug_audio:
                    print("[AUDIO] Using Vosk offline model", flush=True)
            except Exception as e:
                if debug_audio:
                    print(f"[AUDIO] Vosk unavailable: {e}", flush=True)

    mic_kwargs = {}
    if dev_index is not None:
        mic_kwargs["device_index"] = dev_index

    with sr.Microphone(**mic_kwargs) as source:
        try:
            if debug_audio:
                print("[AUDIO] Calibrating for ambient noise…", flush=True)
            r.adjust_for_ambient_noise(source, duration=1.5)
        except Exception as e:
            print(f"[AUDIO] calibration error: {e}", flush=True)

        while not shutdown_event.is_set():
            try:
                if debug_audio:
                    print("[AUDIO] Listening…", flush=True)
                audio = r.listen(source, timeout=2, phrase_time_limit=6)
            except sr.WaitTimeoutError:
                continue
            except Exception as e:
                print(f"[AUDIO] listen error: {e}", flush=True)
                time.sleep(0.3)
                continue

            # Recognize
            text = ""
            if use_vosk:
                try:
                    # Minimal Vosk pass via raw data
                    raw = audio.get_raw_data(convert_rate=16000, convert_width=2)
                    from vosk import KaldiRecognizer

                    rec = KaldiRecognizer(model, 16000)
                    if rec.AcceptWaveform(raw):
                        import json

                        res = json.loads(rec.Result() or "{}")
                        text = (res.get("text") or "").strip()
                    else:
                        res = rec.PartialResult()
                        # fall back to Google if partial only
                        text = ""
                except Exception as e:
                    if debug_audio:
                        print(f"[AUDIO] Vosk error: {e}", flush=True)

            if not text:
                try:
                    text = r.recognize_google(audio, language=language).strip()
                except sr.UnknownValueError:
                    text = ""
                except Exception as e:
                    if debug_audio:
                        print(f"[AUDIO] Google STT error: {e}", flush=True)
                    text = ""

            if text:
                print(f"Recognized: {text}", flush=True)
                try:
                    on_text(text)
                except Exception as e:
                    print(f"[AUDIO] callback error: {e}", flush=True)
            else:
                if debug_audio:
                    print("[AUDIO] (no speech)", flush=True)
#!/usr/bin/env python3
from __future__ import annotations
import os, shlex, subprocess, tempfile, threading, sys

# Optional override, example:
#   export TTS_CMD='espeak-ng -v en-us -s 170 %s'
# Or two-step:    'pico2wave -w %W && aplay %W'
TTS_CMD = os.environ.get("TTS_CMD", "").strip()

_engine = None
_engine_lock = threading.Lock()

def _try_pyttsx3(text: str) -> bool:
    global _engine
    try:
        import pyttsx3
        with _engine_lock:
            if _engine is None:
                _engine = pyttsx3.init()
                rate = _engine.getProperty("rate")
                _engine.setProperty("rate", int(rate * 0.95))
            _engine.say(text)
            _engine.runAndWait()
        print("[TTS] pyttsx3 ok", file=sys.stderr, flush=True)
        return True
    except Exception as e:
        print(f"[TTS] pyttsx3 fail: {e}", file=sys.stderr, flush=True)
        return False

def _try_command(text: str) -> bool:
    if not TTS_CMD:
        return False
    try:
        if "%W" in TTS_CMD:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tf:
                wav = tf.name
            cmd = TTS_CMD.replace("%W", shlex.quote(wav))
            subprocess.run(cmd, shell=True, check=True)
            try: os.unlink(wav)
            except Exception: pass
        else:
            cmd = TTS_CMD.replace("%s", shlex.quote(text))
            subprocess.run(cmd, shell=True, check=True)
        print("[TTS] command ok", file=sys.stderr, flush=True)
        return True
    except Exception as e:
        print(f"[TTS] command fail: {e}", file=sys.stderr, flush=True)
        return False

def _try_espeak(text: str) -> bool:
    try:
        subprocess.run(["espeak-ng", text], check=True)
        print("[TTS] espeak-ng ok", file=sys.stderr, flush=True)
        return True
    except Exception as e:
        print(f"[TTS] espeak-ng fail: {e}", file=sys.stderr, flush=True)
        return False

def _try_pico(text: str) -> bool:
    try:
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tf:
            wav = tf.name
        subprocess.run(["pico2wave", "-w", wav, text], check=True)
        subprocess.run(["aplay", wav], check=True)
        try: os.unlink(wav)
        except Exception: pass
        print("[TTS] pico2wave ok", file=sys.stderr, flush=True)
        return True
    except Exception as e:
        print(f"[TTS] pico2wave fail: {e}", file=sys.stderr, flush=True)
        return False

def say(text: str) -> None:
    text = (text or "").strip()
    if not text:
        return
    # Prefer explicit command if provided
    if _try_command(text): return
    if _try_pyttsx3(text): return
    if _try_espeak(text): return
    _try_pico(text)
# Self-Learning AI

From-scratch evolving AI with speech input + TTS and an AI-only waveform.

## Setup
- `pip install numpy pygame pyaudio pyttsx3 SpeechRecognition`
- Optional offline STT: download a Vosk model and set `VOSK_MODEL_PATH`
- Run: `python3 main.py`  (or `python3 evolve_ai.py` if you prefer the wrapper)

## HTTP Triggers
- `GET /hello`
- `GET /sad`
- `GET /say?text=Your%20message`
import os, threading, time, ctypes
import speech_recognition as sr

from brain import Brain
from network.network_server import app as http_app, serve_async, push

HTTP_PORT = int(os.environ.get("MS_HTTP_PORT", "8089"))
STT_ENGINE = os.environ.get("MS_STT", "vosk").lower()
VOSK_MODEL = os.environ.get("VOSK_MODEL", "").strip()
MIC_NAME   = os.environ.get("MS_MIC_NAME", "").strip()
MIC_INDEX  = os.environ.get("MS_MIC_INDEX", "").strip()

MSG_LISTENING = "Listening..."
MSG_MIC_ERR   = "Mic error - check cable or set MS_MIC_INDEX."

def silence_alsa():
    """Hide harmless ALSA/JACK spam in stderr."""
    try:
        ERROR_HANDLER_FUNC = ctypes.CFUNCTYPE(
            None, ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p, ctypes.c_int, ctypes.c_char_p
        )
        def py_error_handler(filename, line, function, err, fmt):  # noqa: ARG001
            return
        c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)
        asound = ctypes.cdll.LoadLibrary("libasound.so")
        asound.snd_lib_error_set_handler(c_error_handler)
    except Exception:
        pass

silence_alsa()

def list_mics():
    try:
        return sr.Microphone.list_microphone_names()
    except Exception as e:
        push(f"[VOICE] Could not list microphones: {e}")
        return []

def prefer_hardware_index():
    """Pick the *USB/hardware* mic first; avoid 'pulse' unless forced."""
    names = list_mics()
    if MIC_INDEX.isdigit():
        i = int(MIC_INDEX)
        if 0 <= i < len(names):
            push(f"[VOICE] Using forced index {i}: {names[i]}")
            return i

    # Explicit name match
    if MIC_NAME:
        for i, n in enumerate(names):
            if MIC_NAME.lower() in n.lower():
                push(f"[VOICE] Using name -> index {i}: {n}")
                return i

    # Strong hints of a real USB / hw device
    for i, n in enumerate(names):
        lower = n.lower()
        if any(k in lower for k in ("anker", "usb", "hw:", "mic", "microphone")) and "monitor" not in lower:
            push(f"[VOICE] Auto-picked hardware index {i}: {n}")
            return i

    # Fall back to 'pulse' if nothing else
    for i, n in enumerate(names):
        if "pulse" in n.lower():
            push(f"[VOICE] Falling back to pulse index {i}: {n}")
            return i

    # Final fallback
    if names:
        push(f"[VOICE] Using first mic: {names[0]}")
        return 0
    return None

def stt_with_vosk(audio, r: sr.Recognizer):
    if not VOSK_MODEL:
        return ""
    try:
        import vosk, json
        pcm = audio.get_raw_data(convert_rate=16000, convert_width=2)
        model = vosk.Model(VOSK_MODEL)
        rec = vosk.KaldiRecognizer(model, 16000)
        rec.AcceptWaveform(pcm)
        # IMPORTANT: FinalResult() returns the completed transcript for a single chunk
        j = json.loads(rec.FinalResult() or "{}")
        return (j.get("text") or "").strip()
    except Exception as e:
        push(f"[VOICE] Vosk failed: {e}")
        return ""

def stt_with_google(audio, r: sr.Recognizer):
    try:
        return r.recognize_google(audio)
    except Exception as e:
        push(f"[VOICE] Google STT failed: {e}")
        return ""

def transcribe(audio, r: sr.Recognizer):
    if STT_ENGINE in ("vosk", "auto"):
        t = stt_with_vosk(audio, r)
        if t:
            return t
    if STT_ENGINE in ("google", "auto"):
        t = stt_with_google(audio, r)
        if t:
            return t
    return ""

brain = Brain()

def handle_ask(text: str) -> str:
    reply = brain.answer(text)      # only answer; no acknowledgement fluff
    push(reply)                     # show the assistant's reply in UI
    return reply

http_app.config["ON_ASK"] = handle_ask

def voice_loop():
    r = sr.Recognizer()
    r.dynamic_energy_threshold = True
    r.pause_threshold = 0.6
    r.phrase_threshold = 0.25

    idx = prefer_hardware_index()
    if idx is None:
        push(MSG_MIC_ERR)
        return

    try:
        with sr.Microphone(device_index=idx, sample_rate=16000, chunk_size=1024) as source:
            push(MSG_LISTENING)
            try:
                r.adjust_for_ambient_noise(source, duration=0.8)
            except Exception:
                pass
            while True:
                try:
                    audio = r.listen(source, phrase_time_limit=6)
                except Exception as e:
                    push(f"[VOICE] Listen error: {e}")
                    time.sleep(0.5)
                    continue
                text = transcribe(audio, r)
                if not text:
                    continue
                reply = brain.answer(text)
                push(reply)
    except Exception as e:
        push(MSG_MIC_ERR)
        push(f"[VOICE] Could not open microphone: {e}")

def main():
    push("Ready.")
    serve_async(HTTP_PORT)          # HTTP server is alive regardless of mic status
    push("[BOOT] voice_loop()")
    t = threading.Thread(target=voice_loop, daemon=True)
    t.start()
    try:
        while True:
            time.sleep(3600)
    except KeyboardInterrupt:
        pass

if __name__ == "__main__":
    main()
